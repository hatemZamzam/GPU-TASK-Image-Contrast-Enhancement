{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPUTask.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "gu9esdpRvNx-"
      },
      "cell_type": "markdown",
      "source": [
        "# Resources\n",
        "\n",
        "https://devblogs.nvidia.com/even-easier-introduction-cuda/\n",
        "\n",
        "https://developer.nvidia.com/cuda-downloads?target_os=Linux\n",
        "\n",
        "https://sites.google.com/site/5kk70gpu/matrixmul-example\n",
        "\n",
        "https://sites.google.com/site/5kk70gpu/installation\n",
        "\n",
        "https://sites.google.com/site/5kk70gpu/assignment-s/color-conversion\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "IsPzceRIu-7K"
      },
      "cell_type": "markdown",
      "source": [
        "# NVIDIA and System checking"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "MDFs2fMtvkC9"
      },
      "cell_type": "markdown",
      "source": [
        "## Check GPU \n",
        "(2ways)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "d2-fZfiAQ9Ja",
        "outputId": "ffb4753f-896e-46e0-f881-82c25b257325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#check gpu \n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ei4wp_W0vqXB",
        "outputId": "5e4a787b-4a12-47e2-96a3-2ac9644040e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "#Show our GPU specificaion\n",
        "! nvidia-smi"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Dec 30 18:05:09 2018       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    55W / 149W |    116MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lHM-gHeav2NE"
      },
      "cell_type": "markdown",
      "source": [
        "## Check OS"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "b-e8gY8iRE3m",
        "outputId": "6ef61edc-f356-4e8c-fa0e-c470baeaae6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "#check operating system\n",
        "!uname -m && cat /etc/*release"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x86_64\n",
            "DISTRIB_ID=Ubuntu\n",
            "DISTRIB_RELEASE=18.04\n",
            "DISTRIB_CODENAME=bionic\n",
            "DISTRIB_DESCRIPTION=\"Ubuntu 18.04.1 LTS\"\n",
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.1 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.1 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BdueYmROwAvw"
      },
      "cell_type": "markdown",
      "source": [
        "## Check gcc version"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bztLySdHRWZi",
        "outputId": "523225f1-23c9-4bca-c170-4d46bdee596f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "#check gcc version\n",
        "!gcc --version"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gcc (Ubuntu 6.5.0-2ubuntu1~18.04) 6.5.0 20181026\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tDG2XD9YWD56",
        "colab_type": "code",
        "outputId": "c0db0ef8-0537-44d8-f750-e4577c5ec2db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "#cuda need gcc version 6 --> install version 6\n",
        "!apt-get install gcc-6\n",
        "!apt-get install g++-6"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "gcc-6 is already the newest version (6.5.0-2ubuntu1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 12 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "g++-6 is already the newest version (6.5.0-2ubuntu1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 12 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EXRczq6ZwTra"
      },
      "cell_type": "markdown",
      "source": [
        "## Nvidia Driver and Cuda toolkit installation "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Y5s1-CI6WkRe",
        "outputId": "f4201bbb-32c4-4b5e-961d-3c63a972b8bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "!wget \"http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64/cuda-repo-ubuntu1704_9.1.85-1_amd64.deb\"\n",
        "!dpkg -i cuda-repo-ubuntu1704_9.1.85-1_amd64.deb"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-30 18:05:26--  http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64/cuda-repo-ubuntu1704_9.1.85-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 192.229.232.112, 2606:2800:247:2063:46e:21d:825:102e\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|192.229.232.112|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2830 (2.8K) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1704_9.1.85-1_amd64.deb’\n",
            "\n",
            "\r          cuda-repo   0%[                    ]       0  --.-KB/s               \rcuda-repo-ubuntu170 100%[===================>]   2.76K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-12-30 18:05:26 (421 MB/s) - ‘cuda-repo-ubuntu1704_9.1.85-1_amd64.deb’ saved [2830/2830]\n",
            "\n",
            "(Reading database ... 111872 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1704_9.1.85-1_amd64.deb ...\n",
            "Unpacking cuda-repo-ubuntu1704 (9.1.85-1) over (9.1.85-1) ...\n",
            "Setting up cuda-repo-ubuntu1704 (9.1.85-1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QdX_mF9zW3uM",
        "outputId": "d70739a8-98b8-415f-f993-a1517f393959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install dirmngr\n",
        "!apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64/7fa2af80.pub"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 8%\r\rReading package lists... 8%\r\rReading package lists... 8%\r\rReading package lists... 8%\r\rReading package lists... 80%\r\rReading package lists... 80%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 83%\r\rReading package lists... 86%\r\rReading package lists... 86%\r\rReading package lists... 86%\r\rReading package lists... 86%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 96%\r\rReading package lists... 96%\r\rReading package lists... 97%\r\rReading package lists... 97%\r\rReading package lists... 97%\r\rReading package lists... 97%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "dirmngr is already the newest version (2.2.4-1ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 12 not upgraded.\n",
            "Executing: /tmp/apt-key-gpghome.guAPKg7K0f/gpg.1.sh --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64/7fa2af80.pub\n",
            "gpg: requesting key from 'http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64/7fa2af80.pub'\n",
            "gpg: key F60F4B3D7FA2AF80: \"cudatools <cudatools@nvidia.com>\" not changed\n",
            "gpg: Total number processed: 1\n",
            "gpg:              unchanged: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uwWAtiLgXQey",
        "outputId": "37f593d7-6f20-4199-d2bc-84ed4e4b7e63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install cuda"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.149)] [Connecting to security.u\r                                                                               \rHit:2 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64  Release\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.149)] [Connecting to security.u\r0% [Release.gpg gpgv 564 B] [Connecting to archive.ubuntu.com (91.189.88.149)] \r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease\n",
            "\r0% [Release.gpg gpgv 564 B] [Connecting to archive.ubuntu.com (91.189.88.149)] \r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release\n",
            "\r0% [Release.gpg gpgv 564 B] [Connecting to archive.ubuntu.com (91.189.88.149)] \r                                                                               \r0% [Waiting for headers] [Waiting for headers] [Waiting for headers]\r0% [Release.gpg gpgv 564 B] [Waiting for headers] [Waiting for headers] [Waitin\r                                                                               \rGet:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [83.2 kB]\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Fetched 247 kB in 2s (117 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cuda is already the newest version (9.2.148-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 12 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "C0e_-e2yx1nR",
        "outputId": "2fe350ae-7f35-4bd3-9318-a6f92873c760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "#Install CUDA Toolkit\n",
        "#!apt-get install nvidia-cuda-toolkit\n",
        "!nvcc --version   #CUDA files have the file extension .cu. and compile it with nvcc, the CUDA C++ compiler."
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Tue_Jun_12_23:07:04_CDT_2018\n",
            "Cuda compilation tools, release 9.2, V9.2.148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZHu8RLgY3wi3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#linking cuda compiler to gcc 6\n",
        "!ln -s -f /usr/bin/gcc-6 /usr/local/cuda-9.2/bin/gcc\n",
        "!ln -s -f /usr/bin/g++-6 /usr/local/cuda-9.2/bin/g++"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yVjr32NsK1eI",
        "outputId": "3c2afae9-e8e2-446b-b5ba-fe2ab81f232f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#verify that the NVIDIA display driver is installed (unnecessary step)\n",
        "!lspci -v | grep -i nvidia"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: lspci: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LwDM5WZiyDWG"
      },
      "cell_type": "markdown",
      "source": [
        "# Test Cuda samples"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Hf9ErMyD3YZ1"
      },
      "cell_type": "markdown",
      "source": [
        "## browse cuda samples"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vh1I5XfulaXa",
        "outputId": "1515b25b-f30a-4350-f2b4-5effe7a50acb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"*** Listing learning samples downloaded with cuda ***\")\n",
        "!ls /usr/local/cuda-9.2/samples\n",
        "\n",
        "print( \"\\n *** Listing vector add Hello world sample ***\")\n",
        "!ls /usr/local/cuda-9.2/samples/0_Simple/vectorAdd"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** Listing learning samples downloaded with cuda ***\n",
            "0_Simple     2_Graphics  4_Finance\t6_Advanced\t common    Makefile\n",
            "1_Utilities  3_Imaging\t 5_Simulations\t7_CUDALibraries  EULA.txt\n",
            "\n",
            " *** Listing vector add Hello world sample ***\n",
            "Makefile  NsightEclipse.xml  readme.txt  vectorAdd.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "f3x4N6hNybjs",
        "outputId": "9f23ef17-dbd4-4b69-9d90-318d8c7db269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3417
        }
      },
      "cell_type": "code",
      "source": [
        "print( \"\\n *** Checking vectorAdd.cu ***\")\n",
        "!cat /usr/local/cuda-9.2/samples/0_Simple/vectorAdd/vectorAdd.cu"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " *** Checking vectorAdd.cu ***\n",
            "/**\n",
            " * Copyright 1993-2015 NVIDIA Corporation.  All rights reserved.\n",
            " *\n",
            " * Please refer to the NVIDIA end user license agreement (EULA) associated\n",
            " * with this source code for terms and conditions that govern your use of\n",
            " * this software. Any use, reproduction, disclosure, or distribution of\n",
            " * this software and related documentation outside the terms of the EULA\n",
            " * is strictly prohibited.\n",
            " *\n",
            " */\n",
            "\n",
            "/**\n",
            " * Vector addition: C = A + B.\n",
            " *\n",
            " * This sample is a very basic sample that implements element by element\n",
            " * vector addition. It is the same as the sample illustrating Chapter 2\n",
            " * of the programming guide with some additions like error checking.\n",
            " */\n",
            "\n",
            "#include <stdio.h>\n",
            "\n",
            "// For the CUDA runtime routines (prefixed with \"cuda_\")\n",
            "#include <cuda_runtime.h>\n",
            "\n",
            "#include <helper_cuda.h>\n",
            "/**\n",
            " * CUDA Kernel Device code\n",
            " *\n",
            " * Computes the vector addition of A and B into C. The 3 vectors have the same\n",
            " * number of elements numElements.\n",
            " */\n",
            "__global__ void\n",
            "vectorAdd(const float *A, const float *B, float *C, int numElements)\n",
            "{\n",
            "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
            "\n",
            "    if (i < numElements)\n",
            "    {\n",
            "        C[i] = A[i] + B[i];\n",
            "    }\n",
            "}\n",
            "\n",
            "/**\n",
            " * Host main routine\n",
            " */\n",
            "int\n",
            "main(void)\n",
            "{\n",
            "    // Error code to check return values for CUDA calls\n",
            "    cudaError_t err = cudaSuccess;\n",
            "\n",
            "    // Print the vector length to be used, and compute its size\n",
            "    int numElements = 50000;\n",
            "    size_t size = numElements * sizeof(float);\n",
            "    printf(\"[Vector addition of %d elements]\\n\", numElements);\n",
            "\n",
            "    // Allocate the host input vector A\n",
            "    float *h_A = (float *)malloc(size);\n",
            "\n",
            "    // Allocate the host input vector B\n",
            "    float *h_B = (float *)malloc(size);\n",
            "\n",
            "    // Allocate the host output vector C\n",
            "    float *h_C = (float *)malloc(size);\n",
            "\n",
            "    // Verify that allocations succeeded\n",
            "    if (h_A == NULL || h_B == NULL || h_C == NULL)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to allocate host vectors!\\n\");\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Initialize the host input vectors\n",
            "    for (int i = 0; i < numElements; ++i)\n",
            "    {\n",
            "        h_A[i] = rand()/(float)RAND_MAX;\n",
            "        h_B[i] = rand()/(float)RAND_MAX;\n",
            "    }\n",
            "\n",
            "    // Allocate the device input vector A\n",
            "    float *d_A = NULL;\n",
            "    err = cudaMalloc((void **)&d_A, size);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to allocate device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Allocate the device input vector B\n",
            "    float *d_B = NULL;\n",
            "    err = cudaMalloc((void **)&d_B, size);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to allocate device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Allocate the device output vector C\n",
            "    float *d_C = NULL;\n",
            "    err = cudaMalloc((void **)&d_C, size);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to allocate device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Copy the host input vectors A and B in host memory to the device input vectors in\n",
            "    // device memory\n",
            "    printf(\"Copy input data from the host memory to the CUDA device\\n\");\n",
            "    err = cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to copy vector A from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    err = cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to copy vector B from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Launch the Vector Add CUDA Kernel\n",
            "    int threadsPerBlock = 256;\n",
            "    int blocksPerGrid =(numElements + threadsPerBlock - 1) / threadsPerBlock;\n",
            "    printf(\"CUDA kernel launch with %d blocks of %d threads\\n\", blocksPerGrid, threadsPerBlock);\n",
            "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, numElements);\n",
            "    err = cudaGetLastError();\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to launch vectorAdd kernel (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Copy the device result vector in device memory to the host result vector\n",
            "    // in host memory.\n",
            "    printf(\"Copy output data from the CUDA device to the host memory\\n\");\n",
            "    err = cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to copy vector C from device to host (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Verify that the result vector is correct\n",
            "    for (int i = 0; i < numElements; ++i)\n",
            "    {\n",
            "        if (fabs(h_A[i] + h_B[i] - h_C[i]) > 1e-5)\n",
            "        {\n",
            "            fprintf(stderr, \"Result verification failed at element %d!\\n\", i);\n",
            "            exit(EXIT_FAILURE);\n",
            "        }\n",
            "    }\n",
            "\n",
            "    printf(\"Test PASSED\\n\");\n",
            "\n",
            "    // Free device global memory\n",
            "    err = cudaFree(d_A);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to free device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    err = cudaFree(d_B);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to free device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    err = cudaFree(d_C);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to free device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Free host memory\n",
            "    free(h_A);\n",
            "    free(h_B);\n",
            "    free(h_C);\n",
            "\n",
            "    printf(\"Done\\n\");\n",
            "    return 0;\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5cpHJOyllrMt",
        "outputId": "f3d2b2a1-7aca-4f9f-ca42-4ba275fa72c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"*** browse location of all header files used for cuda samples ***\")\n",
        "!ls /usr/local/cuda-9.2/samples/common/inc"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** browse location of all header files used for cuda samples ***\n",
            "cuda_drvapi_dynlink.c  helper_gl.h\t nvVector.h\n",
            "drvapi_error_string.h  helper_image.h\t paramgl.h\n",
            "dynlink\t\t       helper_math.h\t param.h\n",
            "dynlink_d3d10.h        helper_string.h\t rendercheck_d3d10.h\n",
            "dynlink_d3d11.h        helper_timer.h\t rendercheck_d3d11.h\n",
            "exception.h\t       multithreading.h  rendercheck_d3d9.h\n",
            "GL\t\t       nvMath.h\t\t rendercheck_gles.h\n",
            "helper_cuda_drvapi.h   nvMatrix.h\t rendercheck_gl.h\n",
            "helper_cuda.h\t       nvQuaternion.h\t timer.h\n",
            "helper_cusolver.h      nvrtc_helper.h\n",
            "helper_functions.h     nvShaderUtils.h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "PZys8KvyztkW"
      },
      "cell_type": "markdown",
      "source": [
        "## Create our workingSpace"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CxbL7QJnz7qc",
        "outputId": "adb8ca3a-9899-4e51-8148-4afc83d227b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"*** make cuda workspace folder ***\")\n",
        "!mkdir CUDA_Workspace\n",
        "\n",
        "\n",
        "print(\"\\n*** copying vector add sample to our  workspace folder ***\")\n",
        "!cp -r /usr/local/cuda-9.2/samples/0_Simple/vectorAdd/ /content/CUDA_Workspace/vectorAdd\n",
        "\n",
        "print(\"\\n*** cd to the workspace folder ***\")\n",
        "%cd  CUDA_Workspace/vectorAdd\n",
        "\n",
        "!pwd\n",
        "!ls \n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** make cuda workspace folder ***\n",
            "\n",
            "*** copying vector add sample to our  workspace folder ***\n",
            "\n",
            "*** cd to the workspace folder ***\n",
            "[Errno 2] No such file or directory: 'CUDA_Workspace/vectorAdd'\n",
            "/content/CUDA_Workspace/sample2\n",
            "/content/CUDA_Workspace/sample2\n",
            "CMakeCache.txt\t\t\t\t gpu-histogram-equalization.cu\n",
            "CMakeFiles\t\t\t\t hist-equ.h\n",
            "cmake_install.cmake\t\t\t in.pgm\n",
            "CMakeLists.txt\t\t\t\t in.ppm\n",
            "cuda-repo-ubuntu1704_9.1.85-1_amd64.deb  main.cpp\n",
            "CUDA_Workspace\t\t\t\t Makefile\n",
            "gpu-contrast-enhancement.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "cSvhfeoe2itI"
      },
      "cell_type": "markdown",
      "source": [
        "## Compile vectorAdd sample"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4bmRBDKmtLuH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3127d262-5e79-4bc6-c790-a52a5d25148f"
      },
      "cell_type": "code",
      "source": [
        "#compile cuda code\n",
        "!/usr/local/cuda-9.2/bin/nvcc -I /usr/local/cuda-9.2/samples/common/inc vectorAdd.cu -o vectorAddCuda"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[KvectorAdd.cu: No such file or directory\n",
            "\u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K-x c++\u001b[m\u001b[K’ after last input file has no effect\n",
            "\u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Kno input files\n",
            "compilation terminated.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0ReRs4aQunju",
        "outputId": "1995333b-6fd5-4c0b-b9fe-4d0e29df6c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#run cuda output\n",
        "!./vectorAddCuda"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: ./vectorAddCuda: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jC756o7w7oc0"
      },
      "cell_type": "markdown",
      "source": [
        "## Upload from local machine"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NV6LsGUy743h",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#upload file from local machine\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "def uploadFile(fname):\n",
        "\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  ##files.upload returns a dictionary of the files which were uploaded. The \n",
        "  ##dictionary is keyed by the file name, the value is the data which was \n",
        "  ##uploaded.\n",
        "  #fileContent=\"\"\n",
        "  for fn in uploaded.keys():\n",
        "    print(fn,len(uploaded[fn]))\n",
        "    print(uploaded[fn],\"___\") \n",
        "\n",
        "    \n",
        "    #fileContent= uploaded[fn]\n",
        "    #saveFile(fn,fileContent.decode(\"utf-8\"))\n",
        "    break\n",
        "  return uploaded[fname]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m5kYvKOa8A3D",
        "outputId": "ab9229c5-71e8-42ad-9320-8424de3df6b2",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"%cd ..\n",
        "%cd CUDA_Workspace\n",
        "!pwd\n",
        "!mkdir histEq\n",
        "%cd histEq\n",
        "!pwd\"\"\"\n",
        "outString= uploadFile('contrastEnh.cpp')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-321532d5-9b9f-429e-8fc1-f346b398346c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-321532d5-9b9f-429e-8fc1-f346b398346c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving in.pgm to in.pgm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-7017f215c88f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mcd\u001b[0m \u001b[0mhistEq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m !pwd\"\"\"\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moutString\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0muploadFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'contrastEnh.cpp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-83-1226bc45a670>\u001b[0m in \u001b[0;36muploadFile\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#saveFile(fn,fileContent.decode(\"utf-8\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'contrastEnh.cpp'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aoODjMsXHhrr",
        "outputId": "eeb2eec3-64e1-4395-eed3-252b3d95d3fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "cell_type": "code",
      "source": [
        "!cmake ."
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- The C compiler identification is GNU 7.3.0\n",
            "-- The CXX compiler identification is GNU 7.3.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Looking for pthread.h\n",
            "-- Looking for pthread.h - found\n",
            "-- Looking for pthread_create\n",
            "-- Looking for pthread_create - not found\n",
            "-- Looking for pthread_create in pthreads\n",
            "-- Looking for pthread_create in pthreads - not found\n",
            "-- Looking for pthread_create in pthread\n",
            "-- Looking for pthread_create in pthread - found\n",
            "-- Found Threads: TRUE  \n",
            "-- Found CUDA: /usr/local/cuda (found version \"9.2\") \n",
            "-- /usr/local/cuda/include\n",
            "-- /usr/local/cuda\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/CUDA_Workspace/histEq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QVpmRgh-9IC_",
        "outputId": "7be04eb1-8569-4b0e-c2df-a0b862de2f9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "!make\n",
        "#!cat main.cpp"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 16%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/5kk70-assignment-gpu.dir/5kk70-assignment-gpu_generated_gpu-histogram-equalization.cu.o\u001b[0m\n",
            "[ 33%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/5kk70-assignment-gpu.dir/5kk70-assignment-gpu_generated_gpu-contrast-enhancement.cu.o\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target 5kk70-assignment-gpu\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/5kk70-assignment-gpu.dir/main.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/5kk70-assignment-gpu.dir/histogram-equalization.cpp.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object CMakeFiles/5kk70-assignment-gpu.dir/contrast-enhancement.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable 5kk70-assignment-gpu\u001b[0m\n",
            "[100%] Built target 5kk70-assignment-gpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nAm8U5fKYjyH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "de754151-74f0-40fb-b7f2-d9f3dfc127a8"
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "print('Beginning file download with urllib2...')\n",
        "\n",
        "url = 'https://www.freefileconvert.com/file/b0rma5lKarlM/download'  \n",
        "urllib.request.urlretrieve(url, 'in.ppm')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning file download with urllib2...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('in.ppm', <http.client.HTTPMessage at 0x7f60eb096898>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AVQEp_8H9r5Y",
        "outputId": "fd2f74d4-4d47-4825-d1ba-38e709e7f4ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "!./5kk70-assignment-gpu"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================================================\n",
            " Running contrast enhancement for gray-scale images\n",
            "====================================================\n",
            "Image size: 1920 x 1440\n",
            "------------------------\n",
            "Starting CPU processing\n",
            "Processing time: 45.261002 (ms)\n",
            "------------------------\n",
            "Starting GPU processing\n",
            "Processing time: 10.872000 (ms)\n",
            "====================================================\n",
            "    Running contrast enhancement for color images     \n",
            "====================================================\n",
            "Image size: 3648 x 2736\n",
            "-------------------------------------\n",
            "Starting CPU processing\n",
            "-------------------------------------\n",
            "HSL processing time: 1096.609985 (ms)\n",
            "YUV processing time: 644.906982 (ms)\n",
            "RGB processing time: 464.470001 (ms)\n",
            "-------------------------------------\n",
            "Starting GPU processing\n",
            "-------------------------------------\n",
            "HSL processing time: 121.114998 (ms)\n",
            "YUV processing time: 116.834000 (ms)\n",
            "RGB processing time: 103.141998 (ms)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}